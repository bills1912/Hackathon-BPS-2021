{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import Training and Testing Data\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "online_booking_train = pd.read_csv(\"train-online_booking_2020.csv\")\r\n",
    "online_booking_test = pd.read_csv(\"test-online_booking_2021.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Checking Missing Value from the Data\r\n",
    "df1 = online_booking_train.isna().sum()\r\n",
    "df2 = online_booking_test.isna().sum()\r\n",
    "print(\"Data testing:\\n\", df1, \"\\n\")\r\n",
    "print(\"Data training:\\n\", df2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Making the Used Room Dataset\r\n",
    "online_booking_train['room_used'] = online_booking_train['room_total'] - online_booking_train['all_available_room']\r\n",
    "online_booking_test['room_used'] = online_booking_test['room_total'] - online_booking_test['all_available_room']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert the Type of 'tanggal' Column into Datetime Type\r\n",
    "online_booking_train['tanggal'] = pd.to_datetime(online_booking_train['tanggal'])\r\n",
    "online_booking_test['tanggal'] = pd.to_datetime(online_booking_test['tanggal'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(online_booking_train.head())\r\n",
    "print(online_booking_test.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Visualize the Train Data Depend On the Time Aggregate\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "plt.figure(figsize=(12, 8))\r\n",
    "online_booking_train.groupby('tanggal')['room_used'].sum().plot()\r\n",
    "plt.title(\"Jumlah Ruang yang Digunakan Berdasarkan Waktu\", fontsize=15)\r\n",
    "plt.xlabel(\"Waktu\")\r\n",
    "plt.ylabel(\"Jumlah\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Setting the Datetime Dataset ('tanggal') Column to Only Group of Month\r\n",
    "agg_train_online_booking = online_booking_train.set_index('tanggal').resample('M').mean()\r\n",
    "agg_test_online_booking = online_booking_test.set_index('tanggal').resample('M').mean()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "agg_train_online_booking['tpk_online'] = agg_train_online_booking['room_used']/agg_train_online_booking['room_total']*100\r\n",
    "agg_test_online_booking['tpk_online'] = agg_test_online_booking['room_used']/agg_test_online_booking['room_total']*100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Reset the Data Index\r\n",
    "agg_train_online_booking = agg_train_online_booking.reset_index()\r\n",
    "agg_test_online_booking = agg_test_online_booking.reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Set the ID depend on Time Column\r\n",
    "agg_train_online_booking['Id'] = pd.DatetimeIndex(agg_train_online_booking['tanggal']).month\r\n",
    "agg_test_online_booking['Id'] = pd.DatetimeIndex(agg_test_online_booking['tanggal']).month"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import TPK Dataset\r\n",
    "tpk_hotel_berbintang_train = pd.read_csv(\"train-TPK_Hotel_berbintang_2020.csv\")\r\n",
    "tpk_hotel_berbintang_test = pd.read_csv(\"test-TPK_Hotel_berbintang_2021.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Merge All of The Data into a Completed Training and Testing Dataset\r\n",
    "df_full_train = pd.merge(agg_train_online_booking, tpk_hotel_berbintang_train, on='Id', how='left')\r\n",
    "df_full_test = pd.merge(agg_test_online_booking, tpk_hotel_berbintang_test, on='Id', how='left')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(df_full_train.head())\r\n",
    "print(df_full_test.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fill the Aggregate Dataset using The Mean of the Used Room\r\n",
    "agg_value_train = df_full_train.groupby('tanggal')['room_used'].mean()\r\n",
    "agg_value_test = df_full_test.groupby('tanggal')['room_used'].mean()\r\n",
    "\r\n",
    "for x in range(0, 12):\r\n",
    "    df_full_train.loc[:x, 'Aggregate_var'].fillna(agg_value_train[x], inplace=True)\r\n",
    "\r\n",
    "for y in range(0, 6):\r\n",
    "    df_full_test.loc[:y, 'Aggregate'].fillna(agg_value_test[y], inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Making Training and Testing Dataset\r\n",
    "train_ds = df_full_train[['tpk_online','TPK']]\r\n",
    "test_ds = df_full_test[['tpk_online', 'TPK']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Making Training and Testing Dataset\r\n",
    "training = df_full_train[['Aggregate_var', 'tpk_online','TPK']]\r\n",
    "testing = df_full_test[['Aggregate', 'tpk_online', 'TPK']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_training = train_ds['tpk_online']\r\n",
    "y_training = train_ds['TPK']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train_ds = training.drop('TPK', axis=1)\r\n",
    "y_train_ds = training['TPK']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train_ds.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Checking the Normalization of Data\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "plt.figure(figsize=(10,8))\r\n",
    "sns.displot(test_ds, x='tpk_online')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Checking The Outlier\r\n",
    "plt.figure(figsize=(10,8))\r\n",
    "train_ds.boxplot()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Making the Model\r\n",
    "from sklearn.linear_model import Ridge\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "ridge = Ridge()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ridge.get_params()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid = GridSearchCV(ridge, param_grid=dict(\r\n",
    "                                            alpha=np.logspace(3.16, 4, 5),\r\n",
    "                                            solver=['auto', 'svd', 'cholesky', 'lsqr']),\r\n",
    "                                            n_jobs=-1)\r\n",
    "model = grid.fit(X_training.values.reshape(-1,1), y_training.values.reshape(-1,1))\r\n",
    "\r\n",
    "y_pred = model.predict(X_training.values.reshape(-1,1))\r\n",
    "print(\"Model score:\", model.score(X_training.values.reshape(-1,1), y_training.values.reshape(-1,1)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Making the Model\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "dtr = LinearRegression()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = dtr.fit(X_training.values.reshape(-1,1), y_training.values.reshape(-1,1))\r\n",
    "\r\n",
    "y_pred = model.predict(X_training.values.reshape(-1,1))\r\n",
    "print(\"Model score:\", model.score(X_training.values.reshape(-1,1), y_training.values.reshape(-1,1)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Making the Model\r\n",
    "from sklearn.svm import SVR\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "dtr = SVR()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid = GridSearchCV(dtr, param_grid=dict(\r\n",
    "                                        C=np.linspace(1, 10, 10),\r\n",
    "                                        kernel=['linear']),\r\n",
    "                                        n_jobs=-1\r\n",
    "                                        )\r\n",
    "model = grid.fit(X_training.values.reshape(-1,1), y_training.values.reshape(-1,1))\r\n",
    "\r\n",
    "y_pred = model.predict(X_training.values.reshape(-1,1))\r\n",
    "print(\"Model score:\", model.score(X_training.values.reshape(-1,1), y_training.values.reshape(-1,1)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "\r\n",
    "rfc = RandomForestRegressor()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rfc.get_params()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid = GridSearchCV(rfc, param_grid=dict(\r\n",
    "                                        ccp_alpha=np.linspace(1, 10, 10),\r\n",
    "                                        criterion=['mse', 'mae'],\r\n",
    "                                        n_jobs=[1,2,3,4,5,6,7,8,9]),\r\n",
    "                                        n_jobs=-1\r\n",
    "                                        )\r\n",
    "model = grid.fit(X_training.values.reshape(-1,1), y_training.values.reshape(-1,1))\r\n",
    "\r\n",
    "y_pred = model.predict(X_training.values.reshape(-1,1))\r\n",
    "print(\"Model score:\", model.score(X_training.values.reshape(-1,1), y_training.values.reshape(-1,1)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Check the Root Mean Squared Error of the Model\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "mse = mean_squared_error(X_training, y_pred)\r\n",
    "rmse = np.sqrt(mse)\r\n",
    "print(rmse)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Predict the Testing TPK Dataset\r\n",
    "tpk_predict = model.predict(test_ds['tpk_online'].values.reshape(-1,1))\r\n",
    "tpk_predict = tpk_predict.ravel()\r\n",
    "tpk_predict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fill the Resul of the TPK Prediction\r\n",
    "for y in range(0, 6):\r\n",
    "    df_full_test.loc[:y, 'TPK'].fillna(tpk_predict[y], inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_full_test['TPK']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "hasil = pd.DataFrame()\r\n",
    "hasil['Id'] = df_full_test['Id']\r\n",
    "hasil['TPK'] = df_full_test['TPK']\r\n",
    "hasil[['Id', 'TPK']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "hasil[['Id', 'TPK']].to_csv('HASIL_MODEL.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Checking the Confusion Matrix of the Model\r\n",
    "from yellowbrick.regressor import PredictionError\r\n",
    "\r\n",
    "pe = PredictionError(dtr)\r\n",
    "pe.fit(X_training.values.reshape(-1,1), y_training.values.reshape(-1,1))\r\n",
    "pe.score(X_training.values.reshape(-1,1), y_training.values.reshape(-1,1))\r\n",
    "pe.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit"
  },
  "interpreter": {
   "hash": "f23faf4bfe871c203c8bec80520af5927fc7cb1ae3bd834ddf554ee587ad1c05"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}